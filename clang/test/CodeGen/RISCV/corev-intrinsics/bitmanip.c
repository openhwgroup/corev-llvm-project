// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py
// RUN: %clang_cc1 -triple riscv32 -target-feature +xcvbitmanip -emit-llvm %s -o - \
// RUN:     | FileCheck %s

#include <stdint.h>

// CHECK-LABEL: @test_extract(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[A_ADDR:%.*]] = alloca i32, align 4
// CHECK-NEXT:    store i32 [[A:%.*]], ptr [[A_ADDR]], align 4
// CHECK-NEXT:    [[TMP0:%.*]] = load i32, ptr [[A_ADDR]], align 4
// CHECK-NEXT:    [[TMP1:%.*]] = call i32 @llvm.riscv.cv.bitmanip.extract(i32 [[TMP0]], i32 65)
// CHECK-NEXT:    ret i32 [[TMP1]]
//
uint32_t test_extract(uint32_t a) {
	return __builtin_riscv_cv_bitmanip_extract(a, (2 << 5) + 1);
}

// CHECK-LABEL: @test_extractr(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[A_ADDR:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[B_ADDR:%.*]] = alloca i16, align 2
// CHECK-NEXT:    store i32 [[A:%.*]], ptr [[A_ADDR]], align 4
// CHECK-NEXT:    store i16 [[B:%.*]], ptr [[B_ADDR]], align 2
// CHECK-NEXT:    [[TMP0:%.*]] = load i32, ptr [[A_ADDR]], align 4
// CHECK-NEXT:    [[TMP1:%.*]] = load i16, ptr [[B_ADDR]], align 2
// CHECK-NEXT:    [[TMP2:%.*]] = zext i16 [[TMP1]] to i32
// CHECK-NEXT:    [[TMP3:%.*]] = call i32 @llvm.riscv.cv.bitmanip.extract(i32 [[TMP0]], i32 [[TMP2]])
// CHECK-NEXT:    ret i32 [[TMP3]]
//
uint32_t test_extractr(uint32_t a, uint16_t b) {
	return __builtin_riscv_cv_bitmanip_extract(a, b);
}

// CHECK-LABEL: @test_extractu(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[A_ADDR:%.*]] = alloca i32, align 4
// CHECK-NEXT:    store i32 [[A:%.*]], ptr [[A_ADDR]], align 4
// CHECK-NEXT:    [[TMP0:%.*]] = load i32, ptr [[A_ADDR]], align 4
// CHECK-NEXT:    [[TMP1:%.*]] = call i32 @llvm.riscv.cv.bitmanip.extractu(i32 [[TMP0]], i32 65)
// CHECK-NEXT:    ret i32 [[TMP1]]
//
uint32_t test_extractu(uint32_t a) {
	return __builtin_riscv_cv_bitmanip_extractu(a, (2 << 5) + 1);
}

// CHECK-LABEL: @test_extractur(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[A_ADDR:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[B_ADDR:%.*]] = alloca i16, align 2
// CHECK-NEXT:    store i32 [[A:%.*]], ptr [[A_ADDR]], align 4
// CHECK-NEXT:    store i16 [[B:%.*]], ptr [[B_ADDR]], align 2
// CHECK-NEXT:    [[TMP0:%.*]] = load i32, ptr [[A_ADDR]], align 4
// CHECK-NEXT:    [[TMP1:%.*]] = load i16, ptr [[B_ADDR]], align 2
// CHECK-NEXT:    [[TMP2:%.*]] = zext i16 [[TMP1]] to i32
// CHECK-NEXT:    [[TMP3:%.*]] = call i32 @llvm.riscv.cv.bitmanip.extractu(i32 [[TMP0]], i32 [[TMP2]])
// CHECK-NEXT:    ret i32 [[TMP3]]
//
uint32_t test_extractur(uint32_t a, uint16_t b) {
	return __builtin_riscv_cv_bitmanip_extractu(a, b);
}

// CHECK-LABEL: @test_insert(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[A_ADDR:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[C_ADDR:%.*]] = alloca i32, align 4
// CHECK-NEXT:    store i32 [[A:%.*]], ptr [[A_ADDR]], align 4
// CHECK-NEXT:    store i32 [[C:%.*]], ptr [[C_ADDR]], align 4
// CHECK-NEXT:    [[TMP0:%.*]] = load i32, ptr [[A_ADDR]], align 4
// CHECK-NEXT:    [[TMP1:%.*]] = load i32, ptr [[C_ADDR]], align 4
// CHECK-NEXT:    [[TMP2:%.*]] = call i32 @llvm.riscv.cv.bitmanip.insert(i32 [[TMP0]], i32 65, i32 [[TMP1]])
// CHECK-NEXT:    ret i32 [[TMP2]]
//
uint32_t test_insert(uint32_t a, uint32_t c) {
	return __builtin_riscv_cv_bitmanip_insert(a, (2 << 5) + 1, c);
}

// CHECK-LABEL: @test_insertr(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[A_ADDR:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[B_ADDR:%.*]] = alloca i16, align 2
// CHECK-NEXT:    [[C_ADDR:%.*]] = alloca i32, align 4
// CHECK-NEXT:    store i32 [[A:%.*]], ptr [[A_ADDR]], align 4
// CHECK-NEXT:    store i16 [[B:%.*]], ptr [[B_ADDR]], align 2
// CHECK-NEXT:    store i32 [[C:%.*]], ptr [[C_ADDR]], align 4
// CHECK-NEXT:    [[TMP0:%.*]] = load i32, ptr [[A_ADDR]], align 4
// CHECK-NEXT:    [[TMP1:%.*]] = load i16, ptr [[B_ADDR]], align 2
// CHECK-NEXT:    [[TMP2:%.*]] = load i32, ptr [[C_ADDR]], align 4
// CHECK-NEXT:    [[TMP3:%.*]] = zext i16 [[TMP1]] to i32
// CHECK-NEXT:    [[TMP4:%.*]] = call i32 @llvm.riscv.cv.bitmanip.insert(i32 [[TMP0]], i32 [[TMP3]], i32 [[TMP2]])
// CHECK-NEXT:    ret i32 [[TMP4]]
//
uint32_t test_insertr(uint32_t a, uint16_t b, uint32_t c) {
	return __builtin_riscv_cv_bitmanip_insert(a, b, c);
}

// CHECK-LABEL: @test_bclr(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[A_ADDR:%.*]] = alloca i32, align 4
// CHECK-NEXT:    store i32 [[A:%.*]], ptr [[A_ADDR]], align 4
// CHECK-NEXT:    [[TMP0:%.*]] = load i32, ptr [[A_ADDR]], align 4
// CHECK-NEXT:    [[TMP1:%.*]] = call i32 @llvm.riscv.cv.bitmanip.bclr(i32 [[TMP0]], i32 65)
// CHECK-NEXT:    ret i32 [[TMP1]]
//
uint32_t test_bclr(uint32_t a) {
	return __builtin_riscv_cv_bitmanip_bclr(a, (2 << 5) + 1);
}

// CHECK-LABEL: @test_bclrr(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[A_ADDR:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[B_ADDR:%.*]] = alloca i16, align 2
// CHECK-NEXT:    store i32 [[A:%.*]], ptr [[A_ADDR]], align 4
// CHECK-NEXT:    store i16 [[B:%.*]], ptr [[B_ADDR]], align 2
// CHECK-NEXT:    [[TMP0:%.*]] = load i32, ptr [[A_ADDR]], align 4
// CHECK-NEXT:    [[TMP1:%.*]] = load i16, ptr [[B_ADDR]], align 2
// CHECK-NEXT:    [[TMP2:%.*]] = zext i16 [[TMP1]] to i32
// CHECK-NEXT:    [[TMP3:%.*]] = call i32 @llvm.riscv.cv.bitmanip.bclr(i32 [[TMP0]], i32 [[TMP2]])
// CHECK-NEXT:    ret i32 [[TMP3]]
//
uint32_t test_bclrr(uint32_t a, uint16_t b) {
	return __builtin_riscv_cv_bitmanip_bclr(a, b);
}

// CHECK-LABEL: @test_bset(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[A_ADDR:%.*]] = alloca i32, align 4
// CHECK-NEXT:    store i32 [[A:%.*]], ptr [[A_ADDR]], align 4
// CHECK-NEXT:    [[TMP0:%.*]] = load i32, ptr [[A_ADDR]], align 4
// CHECK-NEXT:    [[TMP1:%.*]] = call i32 @llvm.riscv.cv.bitmanip.bset(i32 [[TMP0]], i32 65)
// CHECK-NEXT:    ret i32 [[TMP1]]
//
uint32_t test_bset(uint32_t a) {
	return __builtin_riscv_cv_bitmanip_bset(a, (2 << 5) + 1);
}

// CHECK-LABEL: @test_bsetr(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[A_ADDR:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[B_ADDR:%.*]] = alloca i16, align 2
// CHECK-NEXT:    store i32 [[A:%.*]], ptr [[A_ADDR]], align 4
// CHECK-NEXT:    store i16 [[B:%.*]], ptr [[B_ADDR]], align 2
// CHECK-NEXT:    [[TMP0:%.*]] = load i32, ptr [[A_ADDR]], align 4
// CHECK-NEXT:    [[TMP1:%.*]] = load i16, ptr [[B_ADDR]], align 2
// CHECK-NEXT:    [[TMP2:%.*]] = zext i16 [[TMP1]] to i32
// CHECK-NEXT:    [[TMP3:%.*]] = call i32 @llvm.riscv.cv.bitmanip.bclr(i32 [[TMP0]], i32 [[TMP2]])
// CHECK-NEXT:    ret i32 [[TMP3]]
//
uint32_t test_bsetr(uint32_t a, uint16_t b) {
	return __builtin_riscv_cv_bitmanip_bclr(a, b);
}

// CHECK-LABEL: @test_ff1(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[A_ADDR:%.*]] = alloca i32, align 4
// CHECK-NEXT:    store i32 [[A:%.*]], ptr [[A_ADDR]], align 4
// CHECK-NEXT:    [[TMP0:%.*]] = load i32, ptr [[A_ADDR]], align 4
// CHECK-NEXT:    [[TMP1:%.*]] = call i32 @llvm.riscv.cv.bitmanip.ff1(i32 [[TMP0]])
// CHECK-NEXT:    ret i32 [[TMP1]]
//
uint32_t test_ff1(uint32_t a) {
    return __builtin_riscv_cv_bitmanip_ff1(a);
}

// CHECK-LABEL: @test_fl1(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[A_ADDR:%.*]] = alloca i32, align 4
// CHECK-NEXT:    store i32 [[A:%.*]], ptr [[A_ADDR]], align 4
// CHECK-NEXT:    [[TMP0:%.*]] = load i32, ptr [[A_ADDR]], align 4
// CHECK-NEXT:    [[TMP1:%.*]] = call i32 @llvm.riscv.cv.bitmanip.fl1(i32 [[TMP0]])
// CHECK-NEXT:    ret i32 [[TMP1]]
//
uint32_t test_fl1(uint32_t a) {
    return __builtin_riscv_cv_bitmanip_fl1(a);
}

// CHECK-LABEL: @test_clb(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[A_ADDR:%.*]] = alloca i32, align 4
// CHECK-NEXT:    store i32 [[A:%.*]], ptr [[A_ADDR]], align 4
// CHECK-NEXT:    [[TMP0:%.*]] = load i32, ptr [[A_ADDR]], align 4
// CHECK-NEXT:    [[TMP1:%.*]] = call i32 @llvm.riscv.cv.bitmanip.clb(i32 [[TMP0]])
// CHECK-NEXT:    ret i32 [[TMP1]]
//
uint32_t test_clb(uint32_t a) {
    return __builtin_riscv_cv_bitmanip_clb(a);
}

// CHECK-LABEL: @test_cnt(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[A_ADDR:%.*]] = alloca i32, align 4
// CHECK-NEXT:    store i32 [[A:%.*]], ptr [[A_ADDR]], align 4
// CHECK-NEXT:    [[TMP0:%.*]] = load i32, ptr [[A_ADDR]], align 4
// CHECK-NEXT:    [[TMP1:%.*]] = call i32 @llvm.riscv.cv.bitmanip.cnt(i32 [[TMP0]])
// CHECK-NEXT:    ret i32 [[TMP1]]
//
uint32_t test_cnt(uint32_t a) {
    return __builtin_riscv_cv_bitmanip_cnt(a);
}

// CHECK-LABEL: @test_ror(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[A_ADDR:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[B_ADDR:%.*]] = alloca i32, align 4
// CHECK-NEXT:    store i32 [[A:%.*]], ptr [[A_ADDR]], align 4
// CHECK-NEXT:    store i32 [[B:%.*]], ptr [[B_ADDR]], align 4
// CHECK-NEXT:    [[TMP0:%.*]] = load i32, ptr [[A_ADDR]], align 4
// CHECK-NEXT:    [[TMP1:%.*]] = load i32, ptr [[B_ADDR]], align 4
// CHECK-NEXT:    [[TMP2:%.*]] = call i32 @llvm.riscv.cv.bitmanip.ror(i32 [[TMP0]], i32 [[TMP1]])
// CHECK-NEXT:    ret i32 [[TMP2]]
//
uint32_t test_ror(uint32_t a, uint32_t b) {
    return __builtin_riscv_cv_bitmanip_ror(a, b);
}

// CHECK-LABEL: @test_bitrev(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[A_ADDR:%.*]] = alloca i32, align 4
// CHECK-NEXT:    store i32 [[A:%.*]], ptr [[A_ADDR]], align 4
// CHECK-NEXT:    [[TMP0:%.*]] = load i32, ptr [[A_ADDR]], align 4
// CHECK-NEXT:    [[TMP1:%.*]] = call i32 @llvm.riscv.cv.bitmanip.bitrev(i32 [[TMP0]], i32 1, i32 2)
// CHECK-NEXT:    ret i32 [[TMP1]]
//
uint32_t test_bitrev(uint32_t a) {
    return __builtin_riscv_cv_bitmanip_bitrev(a, 1, 2);
}
